{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering Autoencoder Latent Space\n",
    "-------------------------------------\n",
    "\n",
    "In this notebook, we will use the latent space of the trained autoencoder to cluster the netflow data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load the trained autoencoder\n",
    "-------------------------------------\n",
    "- We previously trained an autoencoder on the netflow data.\n",
    "- The checkpoint path are saved in logs/autoencoder/[VERSION]\n",
    "- We will load the weights of the trained model to run inference\n",
    "- As recall, during the inference phase, we will only use the encoder part of the autoencoder to produce the latent representation of the netflow data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = r\"F:\\Docs\\GS FORMATION\\Machine Learning - Epita\\Network Anomaly detection\\logs\\autoencoder_old\\debug2\\autoencoder-epoch=01-val_loss=0.016.ckpt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html](https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:/Docs/GS FORMATION/Machine Learning - Epita/Network Anomaly detection/logs/autoencoder_old/debug2/autoencoder-epoch=01-val_loss=0.016.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m##########################################################\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m###Write your code Here to load the trained autoencoder###\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m##########################################################\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnetwork_ad\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munsupervised\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautoencoder_lightning\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Autoencoder\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCHECKPOINT_PATH\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:125\u001B[0m, in \u001B[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scripting:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe classmethod `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` cannot be called on an instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please call it on the class type and make sure the return value is used.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m     )\n\u001B[1;32m--> 125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\core\\module.py:1582\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[0;32m   1494\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[0;32m   1495\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1500\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1501\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m   1502\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1580\u001B[0m \n\u001B[0;32m   1581\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1582\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m _load_from_checkpoint(\n\u001B[0;32m   1583\u001B[0m         \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   1584\u001B[0m         checkpoint_path,\n\u001B[0;32m   1585\u001B[0m         map_location,\n\u001B[0;32m   1586\u001B[0m         hparams_file,\n\u001B[0;32m   1587\u001B[0m         strict,\n\u001B[0;32m   1588\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1589\u001B[0m     )\n\u001B[0;32m   1590\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\core\\saving.py:63\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m map_location \u001B[38;5;241m=\u001B[39m map_location \u001B[38;5;129;01mor\u001B[39;00m _default_map_location\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pl_legacy_patch():\n\u001B[1;32m---> 63\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# convert legacy checkpoints to the new format\u001B[39;00m\n\u001B[0;32m     66\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m _pl_migrate_checkpoint(\n\u001B[0;32m     67\u001B[0m     checkpoint, checkpoint_path\u001B[38;5;241m=\u001B[39m(checkpoint_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(checkpoint_path, (\u001B[38;5;28mstr\u001B[39m, Path)) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     68\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:59\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(path_or_url, map_location, weights_only)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload_state_dict_from_url(\n\u001B[0;32m     54\u001B[0m         \u001B[38;5;28mstr\u001B[39m(path_or_url),\n\u001B[0;32m     55\u001B[0m         map_location\u001B[38;5;241m=\u001B[39mmap_location,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     56\u001B[0m         weights_only\u001B[38;5;241m=\u001B[39mweights_only,\n\u001B[0;32m     57\u001B[0m     )\n\u001B[0;32m     58\u001B[0m fs \u001B[38;5;241m=\u001B[39m get_filesystem(path_or_url)\n\u001B[1;32m---> 59\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m     61\u001B[0m         f,\n\u001B[0;32m     62\u001B[0m         map_location\u001B[38;5;241m=\u001B[39mmap_location,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     63\u001B[0m         weights_only\u001B[38;5;241m=\u001B[39mweights_only,\n\u001B[0;32m     64\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsspec\\spec.py:1303\u001B[0m, in \u001B[0;36mAbstractFileSystem.open\u001B[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001B[0m\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1302\u001B[0m     ac \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautocommit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intrans)\n\u001B[1;32m-> 1303\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_open(\n\u001B[0;32m   1304\u001B[0m         path,\n\u001B[0;32m   1305\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m   1306\u001B[0m         block_size\u001B[38;5;241m=\u001B[39mblock_size,\n\u001B[0;32m   1307\u001B[0m         autocommit\u001B[38;5;241m=\u001B[39mac,\n\u001B[0;32m   1308\u001B[0m         cache_options\u001B[38;5;241m=\u001B[39mcache_options,\n\u001B[0;32m   1309\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1310\u001B[0m     )\n\u001B[0;32m   1311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1312\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compr\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsspec\\implementations\\local.py:195\u001B[0m, in \u001B[0;36mLocalFileSystem._open\u001B[1;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_mkdir \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    194\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 195\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LocalFileOpener(path, mode, fs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsspec\\implementations\\local.py:359\u001B[0m, in \u001B[0;36mLocalFileOpener.__init__\u001B[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[0;32m    357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression \u001B[38;5;241m=\u001B[39m get_compression(path, compression)\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocksize \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE\n\u001B[1;32m--> 359\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsspec\\implementations\\local.py:364\u001B[0m, in \u001B[0;36mLocalFileOpener._open\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mclosed:\n\u001B[0;32m    363\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocommit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m--> 364\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression:\n\u001B[0;32m    366\u001B[0m             compress \u001B[38;5;241m=\u001B[39m compr[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'F:/Docs/GS FORMATION/Machine Learning - Epita/Network Anomaly detection/logs/autoencoder_old/debug2/autoencoder-epoch=01-val_loss=0.016.ckpt'"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "###Write your code Here to load the trained autoencoder###\n",
    "##########################################################\n",
    "from network_ad.unsupervised.autoencoder_lightning import Autoencoder\n",
    "model = Autoencoder.load_from_checkpoint(CHECKPOINT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load the netflow data\n",
    "-------------------------------------\n",
    "- We will load the netflow data to get the latent representation of the data\n",
    "- We will use the datamodule to load the data\n",
    "- But we will only use the test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from network_ad.config import VAL_RATIO\n",
    "from network_ad.unsupervised.autoencoder_datamodule import AutoencoderDataModule\n",
    "BATCH_SIZE = 64\n",
    "data_module = AutoencoderDataModule(batch_size=BATCH_SIZE, val_ratio=VAL_RATIO)\n",
    "data_module.setup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###Write your code here to get print a sample ############\n",
    "##########################################################\n",
    "#1. Train dataloader\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "first_batch= next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_batch.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Inference\n",
    "-------------------------------------\n",
    "- We will use the encoder part of the autoencoder to get the latent representation of the netflow data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "###################################################################\n",
    "## Write your code here to get the latent representation##########\n",
    "## TIPS: You should write a loop to iterate over the test dataloader\n",
    "###################################################################\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "test_outputs = []\n",
    "\n",
    "for batch in tqdm(test_dataloader, \"Running inference on test dataloader\"):\n",
    "    test_outputs.append(model.encoder(batch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "outputs =torch.concat(test_outputs, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Latent Space Visualization\n",
    "-------------------------------------\n",
    "- Make use of the plotly library to visualize the latent space\n",
    "- We will first perform PCA on the latent space to reduce the dimensionality to 3 or 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Perform PCA\n",
    "\n",
    "- Principal component analysis (PCA) is a technique used to emphasize variation and bring out strong patterns in a dataset. It's often used to make data easy to explore and visualize.\n",
    "- We will use the PCA class from the sklearn library to perform PCA on the latent space"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###Write your code here to perform PCA####################\n",
    "# Recommendation :  Use 3 principal components and create\n",
    "# a new dataframe with the columns ['PC1', 'PC2', 'PC3']\n",
    "##########################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.2 Visualize the latent space\n",
    "\n",
    "-------------------------------------\n",
    "- Make use of the plotly scatter plot to visualize the latent space\n",
    "[https://plotly.com/python/hover-text-and-formatting/](https://plotly.com/python/hover-text-and-formatting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.1 Load some raw data to  annotate the plot\n",
    "\n",
    "We use the following columns: 'HOST_IPV4_SRC_ADDR', 'HOST_IPV4_DST_ADDR','MAX_TTL',\n",
    "'Label','Attack'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We use the method load_data that we have implemented in the datamodule\n",
    "df =data_module.load_data(mode=\"test\")\n",
    "# ONnly keep the columns that we need\n",
    "df = df[['NETWORK_IPV4_SRC_ADDR', 'NETWORK_IPV4_DST_ADDR','MAX_TTL', 'Label','Attack']]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.2.  Visualize the latent space in 2D\n",
    "\n",
    "----------------------------------------------\n",
    "- Use the 2 principal components to visualize the latent space in 2D\n",
    "- Use the plotly scatter3d to visualize the latent space\n",
    "- At this stage, you can use the argument `hover_data` px.scatter to display the columns 'HOST_IPV4_SRC_ADDR', 'HOST_IPV4_DST_ADDR','MAX_TTL',\n",
    "- Make sure to update the dataset of principal components with the columns ['HOST_IPV4_SRC_ADDR', 'HOST_IPV4_DST_ADDR','MAX_TTL']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Write your code here to visualize the latent space in 3D##\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2.3.  Visualize the latent space in 3D\n",
    "----------------------------------------------\n",
    "- Similarly, use the 3 principal components to visualize the latent space in 3D\n",
    "- Use the plotly scatter3d to visualize the latent space\n",
    "- Example : [https://plotly.com/python/3d-scatter-plots/](https://plotly.com/python/3d-scatter-plots/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Write your code here to visualize the latent space in 3D##\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Clustering\n",
    "\n",
    "-------------------------------------\n",
    "- Now let's use the KMeans algorithm to cluster the latent space\n",
    "- We will use the KMeans class from the sklearn library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## 5.1 KMeans Clustering with a fixed number of clusters\n",
    "-------------------------------------\n",
    "- We will first use a fixed number of clusters to perform the clustering\n",
    "- We perform clutering then update the dataframe with the cluster label\n",
    "- We will then visualize the clusters in 2D and 3D by coloring the points according to the cluster label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO : Define the number of clusters below\n",
    "N_CLUTERS =  None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###Write your code here to perform KMeans clustering######\n",
    "## TIPS : Don't use the PCA components but the full\n",
    "## dimension of the latent space\n",
    "##########################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###Update the dataframe with the cluster label.############\n",
    "##Recommendation : Add a new column 'Cluster' to the dataframe\n",
    "##########################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the clusters (In 2D and 3D)\n",
    "----------------------------------------------\n",
    "- It is similar to the step 4.2.2 and 4.2.3 but this time we will color the points according to the cluster label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Write your code here to visualize the clusters in 2D and 3D##\n",
    "## Recommendation : Do not copy code but refactor to create a\n",
    "## visualization function that takes the dataframe and the\n",
    "## columns to visualize as arguments\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 5.2 KMeans Clustering with an optimal number of clusters\n",
    "-------------------------------------\n",
    "- We will use the elbow method to find the optimal number of clusters\n",
    "- We run the KMeans algorithm with a range of number of clusters and plot the inertia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_CLUSTERS =  list(range(1, 16))  # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_clusters_and_inertia = dict() # Store the number of clusters and the inertia\n",
    "##########################################################\n",
    "###Write your code here to perform KMeans clustering######\n",
    "## A loop that will iterate over the number of clusters\n",
    "##########################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Inertia plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Write your code here to plot the inertia vs the number of clusters##\n",
    "## Use matplotlib or plotly\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## TODO : Guess the optimal number of clusters visually by looking at the elbow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Elbow Method (programmatically)\n",
    "-------------------------------------\n",
    "The following code will help you to find the optimal number of clusters programmatically"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_optimal_number_of_clusters(num_clusters_and_inertia):\n",
    "    \"\"\"\n",
    "    Find the optimal number of clusters using the elbow method\n",
    "    \"\"\"\n",
    "    # Compute the first derivative of the inertia\n",
    "    first_derivative = np.diff(list(num_clusters_and_inertia.values()), 1)\n",
    "    # Compute the second derivative of the inertia\n",
    "    second_derivative = np.diff(first_derivative, 1)\n",
    "    # Find the optimal number of clusters\n",
    "    optimal_number_of_clusters = np.where(second_derivative == max(second_derivative))[0][0] + 2\n",
    "    return optimal_number_of_clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Question : Is your guess correct? (Run the function find_optimal_number_of_clusters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Visualize the clusters with the optimal number of clusters(2D and 3D)##\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3  KMeans clustering and True Labels\n",
    "-------------------------------------\n",
    "- No that the true labels are available in the dataframe\n",
    "   - Binary labels in the column 'Label'\n",
    "    - Multiclass labels in the column 'Attack'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#############################################################\n",
    "###Write your code here to visualize the clusters with the true labels(2D and 3D)##\n",
    "### TODO : Color the points according to the true labels\n",
    "##  Compare the clusters with the true labels (Visual inspection)\n",
    "#############################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Question : Are the clusters consistent with the true labels?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Clustering Characterization\n",
    "-------------------------------------\n",
    "- In this last section, we characterize clusters by analysing the similarity between the points in the same cluster\n",
    "\n",
    " *Global Question* : What are the features common to the points in the same cluster?\n",
    "\n",
    "- Guidelines:\n",
    "  - Enrich the dataframe with other columns ( features) that was used to train the autoencoder\n",
    "  - Choose of the features that you think are relevant to characterize the clusters\n",
    "  - In the plotly scatter plot, use the argument `hover_data` to display the columns that you have chosen\n",
    "  - Visualize guess the common properties of the points in the same cluster\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}